\chapter{Literature Review}
\thispagestyle{empty}
In this chapter we will shortly describe history of text classification and learn about different machine learning methods which are really useful for classifying text.This chapter also contains brief discussion on related previous works.

\section{History of Text Classification}
Text classification (or text categorization)  first emerged in the late 1990s as ``Text Data Mining" and has been actively investigated by many researchers. Text classification is a preprocessing technology which can be used to filter out irrelevant documents from a large-scale corpus. In early approaches a text source is treated as bag-of-words. The bag-of-words is a simple representation in which a sentence or a document is expressed by a set of words and it is used in natural language processing. But there was no ability to understand the semantics of a document in earlier approaches.\par
\vspace{.5cm}
After early ages, researchers try to find out hidden relationships and other complex pattern within data-sets. Techniques such as clustering, classification, decision trees and link analysis are used to find out these complex relational patterns. This techniques coupled with machine learning algorithms helps to find deeper linguistics that enable to understand the semantics of a document or a sentence. Text classification helps to allocate documents into predefined topics, such as economics, politics, news, sports etc. Due to the excessive increase in online textual information, e.g., email messages, online news, web pages, as well as a huge number of resources for scientific online abstracts such as MEDLINE, there is an ever-growing demand for text classification. It has now become one of the most attractive research topic. If a system can classify texts accurately we can use it to predict events which will happen in future from our present data. Such as from suspicious communication we may predict a terrorist event. It is an interesting question how to achieve high performance in the task of assigning multiple topics to documents in a targeted domain as the system has to process huge amount of data. If we can develop system with high information processing capacity there will be revolution because this an era of information.


\section{Different Methods of Text Classification}
Many works have already done in text categorization such as spam classification, research paper categorization, detecting suspicious profile using text classification etc.There are several well-known methods and algorithms are already exist for text classification problem such as Na√Øve Bayes Classifier, Support Vector Machine, Decision Tree, Logistic regression, K-nearest neighbor algorithms (KNN) etc.

\subsection{Naive Bayes Classifier}

Naive Bayes is a probabilistic classifier commonly used in machine learning. The Bayesian classifiers are statistical and also possess learning ability. For processing large data-set multinomial model of Naive Bayes is used. By searching the dependencies among attributes the performance of Naive Bayes could be enhanced. It is mainly used in data preprocessing applications due to ease of computation. Bayesian reasoning and probability inference are employed in predicting the target class. Attributes are key in classification using probabilistic model. So weight values of attributes play an important role to improve the performance of the model. %Deep feature weighting solves the problem of conditional independence assumption, which is a major improvement of Naive Bayesian classifier and computes conditional probability accurately. But these feature weighting techniques come with some defects like, inadequate improvement to performance, compromised simplicity and increased execution time of models etc. 
\par
\vspace{0.5cm}
The performance of Naive Bayes depends on the accuracy of the estimated conditional probability terms. When training data is scatter it is hard to estimate conditional probability terms accurately. Some meta learning methods are followed to estimate conditional probability terms. To improve this, various meta-learning techniques such as structure extension, attribute selection, frequency transforming, attribute weighting, instance weighting, and local learning are used. Naive Bayes classifier is applied to mark email as spam/ham, classify articles based on content,sentiment/emotion analysis.% In our project it can also be used classify texts into suspicious and non-suspicious category.
The advantage of Naive Bayesian classifiers are these classifiers are simple and  powerful in terms of degree of certainty, optimization is less complicated and allows for dynamic adaption.These qualities  make them an easier option for handling natural language processing problems. \par
\vspace{.5cm}
The main limitation of Bayesian networks is that the time complexity increases when high dimensional text data is processed using these networks. Moreover, in Bayesian networks interaction between features can not be achieved and the probabilities calculated are not accurate but relative probability.

\subsection{Support Vector Machine}